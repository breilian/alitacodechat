{
  "model": {
    "model_name": "gpt-4o"
  },
  "temperature": 0.8,
  "max_tokens": 4096,
  "top_p": 0.8,
  "top_k": 40,
  "stream": true
}